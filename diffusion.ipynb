{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.distributions as tdist\n",
    "\n",
    "import dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiffusionModel(nn.Module):\n",
    "    def __init__(self, beta):\n",
    "        super(DiffusionModel, self).__init__()\n",
    "        self.device = device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.beta = beta.to(self.device) # Decay schedule\n",
    "        self.T = beta.shape[0]\n",
    "        \n",
    "        self.c1 = nn.Conv2d(1, 10, 3, padding=1)\n",
    "        self.b1 = nn.GroupNorm(1, 10)\n",
    "        \n",
    "        self.c2 = nn.Conv2d(10, 10, 3, padding=1)\n",
    "        self.b2 = nn.GroupNorm(1, 10)\n",
    "        \n",
    "        self.c3 = nn.Conv2d(10, 10, 3, padding=1)\n",
    "        self.b3 = nn.GroupNorm(1, 10)\n",
    "        \n",
    "        self.c4 = nn.Conv2d(10, 10, 3, padding=1)\n",
    "        self.b4 = nn.GroupNorm(1, 10)\n",
    "        \n",
    "        self.c5 = nn.Conv2d(10, 10, 3, padding=1)\n",
    "        self.b5 = nn.GroupNorm(1, 10)\n",
    "        \n",
    "        self.c6 = nn.Conv2d(10, 10, 3, padding=1)\n",
    "        self.b6 = nn.GroupNorm(1, 10)\n",
    "        \n",
    "        self.c7 = nn.Conv2d(10, 10, 3, padding=1)\n",
    "        self.b7 = nn.GroupNorm(1, 10)\n",
    "        \n",
    "        self.c8 = nn.Conv2d(10, 10, 3, padding=1)\n",
    "        self.b8 = nn.GroupNorm(1, 10)\n",
    "        \n",
    "        self.c9 = nn.Conv2d(10, 10, 3, padding=1)\n",
    "        self.b9 = nn.GroupNorm(1, 10)\n",
    "        \n",
    "        self.c10 = nn.Conv2d(10, 10, 3, padding=1)\n",
    "        self.b10 = nn.GroupNorm(1, 10)\n",
    "        \n",
    "        self.c11 = nn.Conv2d(10, 10, 3, padding=1)\n",
    "        self.b11 = nn.GroupNorm(1, 10)\n",
    "        \n",
    "        self.c12 = nn.Conv2d(10, 10, 3, padding=1)\n",
    "        self.b12 = nn.GroupNorm(1, 10)\n",
    "        \n",
    "        self.c13 = nn.Conv2d(10, 1, 3, padding=1)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def alphabar(self, t):\n",
    "        alpha = torch.zeros(t.shape[0], device=self.device)\n",
    "        for idx, s in enumerate(t):\n",
    "            alpha[idx] = torch.prod(1 - self.beta[0:s])\n",
    "        return alpha\n",
    "    \n",
    "    def embedtime(self, t, embedding_size, dimensions):\n",
    "        w = 1.0 / (10000 ** (torch.arange(0, embedding_size, 2, dtype=torch.float32) / embedding_size))\n",
    "        y = torch.sin(t.view(t.shape[0], 1).repeat(1, embedding_size // 2) * w)\n",
    "        x = torch.cos(t.view(t.shape[0], 1).repeat(1, embedding_size // 2) * w)\n",
    "        return torch.cat([x, y], dim=1).view(-1, embedding_size, 1, 1).repeat(1, 1, dimensions, dimensions)\n",
    "    \n",
    "    def sample_image(self):\n",
    "        samples = torch.zeros((self.T + 1, 784), device=self.device)\n",
    "        \n",
    "        samples[self.T] = torch.randn(784, device=self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for t in torch.arange(self.T - 1, 0, -1):\n",
    "                beta = self.beta[t]\n",
    "                alfa = 1 - beta\n",
    "                alfabar = self.alphabar(torch.tensor([t + 1], device=self.device))\n",
    "                z = torch.randn(784, device=self.device)\n",
    "                xt = samples[t + 1]\n",
    "                eps = self.forward(xt.view(1, 1, 28, 28), torch.tensor([t + 1], device=self.device)).view(784)\n",
    "                samples[t] = (xt - beta * eps / (torch.sqrt(1 - alfabar))) / torch.sqrt(alfa) + torch.sqrt(beta) * z\n",
    "            \n",
    "            beta = self.beta[0]\n",
    "            alfa = 1 - beta\n",
    "            alfabar  = self.alphabar(torch.tensor([1], device=self.device))\n",
    "            xt = samples[1]\n",
    "            eps = self.forward(xt.view(1, 1, 28, 28), torch.tensor([1], device=self.device)).view(784)\n",
    "            samples[0] = (xt - beta * eps / (torch.sqrt(1 - alfabar))) / torch.sqrt(alfa)\n",
    "        \n",
    "        return samples\n",
    "        \n",
    "    def forward(self, x, t):\n",
    "        T = self.embedtime(t, 10, 28)\n",
    "        \n",
    "        x = self.c1(x) + T\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.c2(x) + T\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.c3(x) + T\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.c4(x) + T\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.c5(x) + T\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.c6(x) + T\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.c7(x) + T\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.c8(x) + T\n",
    "        x = self.b8(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.c9(x) + T\n",
    "        x = self.b9(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.c10(x) + T\n",
    "        x = self.b10(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.c11(x) + T\n",
    "        x = self.b11(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.c12(x) + T\n",
    "        x = self.b12(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.c13(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_diff(epoch, model, optimizer, loss_function, train_loader):\n",
    "    model.train() # so that everything was gradients and we can do backprop and so on...\n",
    "    train_loss = 0\n",
    "    input = torch.zeros((train_loader.batch_size, 784), device = model.device)\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = data.view(-1, 784)\n",
    "        optimizer.zero_grad() # \"reset\" gradients to 0 for text iteration\n",
    "        \n",
    "        t = torch.randint(1, model.T, (train_loader.batch_size,))\n",
    "        eps = torch.normal(0, 1, (train_loader.batch_size, 784))\n",
    "        alf = model.alphabar(t)\n",
    "        for idx, x in enumerate(data):\n",
    "            input[idx] = torch.sqrt(alf[idx]) * data[idx] + torch.sqrt(1 - alf[idx]) * eps[idx]\n",
    "        eps_nn = model(input.view(-1, 1, 28, 28), t)\n",
    "        loss = loss_function(eps.view(-1, 784), eps_nn.view(-1, 784))\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step() # backpropagation\n",
    "        \n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "          epoch, train_loss / len(train_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DiffusionModel(torch.linspace(1e-4, 0.02, 1000))\n",
    "loss = nn.MSELoss()\n",
    "train_loader, test_loader = dataloader.setup_data_loaders(batch_size=512, use_cuda=False)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m EPOCHS \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(EPOCHS):\n\u001b[0;32m----> 3\u001b[0m     train_diff(epoch, model, optimizer, loss, train_loader)\n",
      "Cell \u001b[0;32mIn[68], line 14\u001b[0m, in \u001b[0;36mtrain_diff\u001b[0;34m(epoch, model, optimizer, loss_function, train_loader)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39mfor\u001b[39;00m idx, x \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(data):\n\u001b[1;32m     13\u001b[0m     \u001b[39minput\u001b[39m[idx] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msqrt(alf[idx]) \u001b[39m*\u001b[39m data[idx] \u001b[39m+\u001b[39m torch\u001b[39m.\u001b[39msqrt(\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m alf[idx]) \u001b[39m*\u001b[39m eps[idx]\n\u001b[0;32m---> 14\u001b[0m eps_nn \u001b[39m=\u001b[39m model(\u001b[39minput\u001b[39;49m\u001b[39m.\u001b[39;49mview(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m, \u001b[39m28\u001b[39;49m, \u001b[39m28\u001b[39;49m), t)\n\u001b[1;32m     15\u001b[0m loss \u001b[39m=\u001b[39m loss_function(eps\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m784\u001b[39m), eps_nn\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m784\u001b[39m))\n\u001b[1;32m     16\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[67], line 107\u001b[0m, in \u001b[0;36mDiffusionModel.forward\u001b[0;34m(self, x, t)\u001b[0m\n\u001b[1;32m    104\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mb4(x)\n\u001b[1;32m    105\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(x)\n\u001b[0;32m--> 107\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mc5(x) \u001b[39m+\u001b[39m T\n\u001b[1;32m    108\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mb5(x)\n\u001b[1;32m    109\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(x)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    460\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "for epoch in range(EPOCHS):\n",
    "    train_diff(epoch, model, optimizer, loss, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = model.sample_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f01f1b91990>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sigmoid = nn.Sigmoid()\n",
    "plt.imshow(test[500].view(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedtime(self, t, embedding_size, dimensions):\n",
    "    emb = torch.zeros((embedding_size // 2) * t.shape[0]).reshape(t.shape[0], embedding_size // 2)\n",
    "    emb2 = torch.zeros((embedding_size // 2) * t.shape[0]).reshape(t.shape[0], embedding_size // 2)\n",
    "    s = torch.linspace(torch.tensor(2), torch.tensor(embedding_size // 2), torch.tensor(embedding_size // 2, dtype=int))\n",
    "    for idx, samp in enumerate(t):\n",
    "        emb[idx] = torch.sin(2 * s * torch.pi * samp / self.T)\n",
    "        emb2[idx] = torch.cos(2 * s * torch.pi * samp / self.T)\n",
    "\n",
    "    return torch.cat([emb, emb2], dim = 1).view(-1, embedding_size, 1, 1).repeat(1, 1, dimensions, dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 8, 8])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 8])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_encoding(self, t, channels, embed_size):\n",
    "        inv_freq = 1.0 / (\n",
    "            10000\n",
    "            ** (torch.arange(0, channels, 2, device=self.device).float() / channels)\n",
    "        )\n",
    "        pos_enc_a = torch.sin(t.repeat(1, channels // 2) * inv_freq)\n",
    "        pos_enc_b = torch.cos(t.repeat(1, channels // 2) * inv_freq)\n",
    "        pos_enc = torch.cat([pos_enc_a, pos_enc_b], dim=-1)\n",
    "        return pos_enc.view(-1, channels, 1, 1).repeat(1, 1, embed_size, embed_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 16])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([2]).repeat(1, 32 // 2) * torch.arange(0, 32, 2)\n",
    "b = a = torch.tensor([2]).repeat(1, 32 // 2) * torch.arange(0, 32, 2)\n",
    "torch.cat([a, b], dim = 1).view(-1, 32, 1, 1).repeat(1, 1, 16, 16)[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
