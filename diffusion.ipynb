{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.distributions as tdist\n",
    "\n",
    "import dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 10, 28, 28])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.linspace(0, 10, 256 * 784).view(-1, 1, 28, 28)\n",
    "\n",
    "c1 = nn.Conv2d(1, 10, 3, padding=1)\n",
    "p1 = nn.LayerNorm([28, 28])\n",
    "\n",
    "p1(c1(x)).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiffusionModel(nn.Module):\n",
    "    def __init__(self, beta):\n",
    "        super(DiffusionModel, self).__init__()\n",
    "        self.device = device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.beta = beta.to(self.device) # Decay schedule\n",
    "        self.T = beta.shape[0]\n",
    "        \n",
    "        self.c1 = nn.Conv2d(1, 10, 3, padding=1)\n",
    "        self.b1 = nn.LayerNorm([28, 28])\n",
    "        \n",
    "        self.c2 = nn.Conv2d(10, 10, 3, padding=1)\n",
    "        self.b2 = nn.LayerNorm([28, 28])\n",
    "        \n",
    "        self.c3 = nn.Conv2d(10, 10, 3, padding=1)\n",
    "        self.b3 = nn.LayerNorm([28, 28])\n",
    "        \n",
    "        self.c4 = nn.Conv2d(10, 10, 3, padding=1)\n",
    "        self.b4 = nn.LayerNorm([28, 28])\n",
    "        \n",
    "        self.c5 = nn.Conv2d(10, 10, 3, padding=1)\n",
    "        self.b5 = nn.LayerNorm([28, 28])\n",
    "        \n",
    "        self.c6 = nn.Conv2d(10, 10, 3, padding=1)\n",
    "        self.b6 = nn.LayerNorm([28, 28])\n",
    "        \n",
    "        self.c7 = nn.Conv2d(10, 10, 3, padding=1)\n",
    "        self.b7 = nn.LayerNorm([28, 28])\n",
    "        \n",
    "        self.c8 = nn.Conv2d(10, 10, 3, padding=1)\n",
    "        self.b8 = nn.LayerNorm([28, 28])\n",
    "        \n",
    "        self.c9 = nn.Conv2d(10, 10, 3, padding=1)\n",
    "        self.b9 = nn.LayerNorm([28, 28])\n",
    "        \n",
    "        self.c10 = nn.Conv2d(10, 10, 3, padding=1)\n",
    "        self.b10 = nn.LayerNorm([28, 28])\n",
    "        \n",
    "        self.c11 = nn.Conv2d(10, 10, 3, padding=1)\n",
    "        self.b11 = nn.LayerNorm([28, 28])\n",
    "        \n",
    "        self.c12 = nn.Conv2d(10, 10, 3, padding=1)\n",
    "        self.b12 = nn.LayerNorm([28, 28])\n",
    "        \n",
    "        self.c13 = nn.Conv2d(10, 1, 3, padding=1)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def alphabar(self, t):\n",
    "        alpha = torch.zeros(t.shape[0], device=self.device)\n",
    "        for idx, s in enumerate(t):\n",
    "            alpha[idx] = torch.prod(1 - self.beta[0:s])\n",
    "        return alpha\n",
    "    \n",
    "    def embedtime(self, t, embedding_size, dimensions):\n",
    "        emb = torch.zeros((embedding_size // 2) * t.shape[0], device=self.device).reshape(t.shape[0], embedding_size // 2)\n",
    "        emb2 = torch.zeros((embedding_size // 2) * t.shape[0], device=self.device).reshape(t.shape[0], embedding_size // 2)\n",
    "        s = torch.linspace(2, embedding_size // 2, embedding_size // 2, device=self.device)\n",
    "        for idx, samp in enumerate(t):\n",
    "            emb[idx] = torch.sin(2 * s * torch.pi * samp / self.T)\n",
    "            emb2[idx] = torch.cos(2 * s * torch.pi * samp / self.T)\n",
    "\n",
    "        return torch.cat([emb, emb2], dim = 1).view(-1, embedding_size, 1, 1).repeat(1, 1, dimensions, dimensions)\n",
    "    \n",
    "    def sample_image(self):\n",
    "        samples = torch.zeros((self.T + 1, 784), device=self.device)\n",
    "        \n",
    "        samples[self.T] = torch.randn(784, device=self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for t in torch.arange(self.T - 1, 0, -1):\n",
    "                beta = self.beta[t]\n",
    "                alfa = 1 - beta\n",
    "                alfabar = self.alphabar(torch.tensor([t + 1], device=self.device))\n",
    "                z = torch.randn(784, device=self.device)\n",
    "                xt = samples[t + 1]\n",
    "                eps = self.forward(xt.view(1, 1, 28, 28), torch.tensor([t + 1], device=self.device)).view(784)\n",
    "                samples[t] = (xt - beta * eps / (torch.sqrt(1 - alfabar))) / torch.sqrt(alfa) + torch.sqrt(beta) * z\n",
    "            \n",
    "            beta = self.beta[0]\n",
    "            alfa = 1 - beta\n",
    "            alfabar  = self.alphabar(torch.tensor([1], device=self.device))\n",
    "            xt = samples[1]\n",
    "            eps = self.forward(xt.view(1, 1, 28, 28), torch.tensor([1], device=self.device)).view(784)\n",
    "            samples[0] = (xt - beta * eps / (torch.sqrt(1 - alfabar))) / torch.sqrt(alfa)\n",
    "        \n",
    "        return samples\n",
    "        \n",
    "    def forward(self, x, t):\n",
    "        T = self.embedtime(t, 10, 28)\n",
    "        \n",
    "        x = self.c1(x) + T\n",
    "        x = self.b1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.c2(x) + T\n",
    "        x = self.b2(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.c3(x) + T\n",
    "        x = self.b3(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.c4(x) + T\n",
    "        x = self.b4(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.c5(x) + T\n",
    "        x = self.b5(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.c6(x) + T\n",
    "        x = self.b6(x)\n",
    "        x = self.relu(x)\n",
    "        print(x.shape)\n",
    "        x = self.c7(x) + T\n",
    "        x = self.b7(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.c8(x) + T\n",
    "        x = self.b8(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.c9(x) + T\n",
    "        x = self.b9(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.c10(x) + T\n",
    "        x = self.b10(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.c11(x) + T\n",
    "        x = self.b11(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.c12(x) + T\n",
    "        x = self.b12(x)\n",
    "        x = self.relu(x)\n",
    "        print(x.shape)\n",
    "        x = self.c13(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_diff(epoch, model, optimizer, loss_function, train_loader):\n",
    "    model.train() # so that everything was gradients and we can do backprop and so on...\n",
    "    train_loss = 0\n",
    "    input = torch.zeros((train_loader.batch_size, 784), device = model.device)\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = data.view(-1, 784)\n",
    "        optimizer.zero_grad() # \"reset\" gradients to 0 for text iteration\n",
    "        \n",
    "        t = torch.randint(1, model.T, (train_loader.batch_size,))\n",
    "        eps = torch.normal(0, 1, (train_loader.batch_size, 784))\n",
    "        alf = model.alphabar(t)\n",
    "        for idx, x in enumerate(data):\n",
    "            input[idx] = torch.sqrt(alf[idx]) * data[idx] + torch.sqrt(1 - alf[idx]) * eps[idx]\n",
    "        eps_nn = model(input.view(-1, 1, 28, 28), t)\n",
    "        loss = loss_function(eps.view(-1, 784), eps_nn.view(-1, 784))\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step() # backpropagation\n",
    "        \n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "          epoch, train_loss / len(train_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DiffusionModel(torch.linspace(1e-4, 0.02, 1000))\n",
    "loss = nn.MSELoss()\n",
    "train_loader, test_loader = dataloader.setup_data_loaders(batch_size=512, use_cuda=False)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 10, 28, 28])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [10, 1, 3, 3], expected input[512, 10, 28, 28] to have 1 channels, but got 10 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m EPOCHS \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(EPOCHS):\n\u001b[0;32m----> 3\u001b[0m     train_diff(epoch, model, optimizer, loss, train_loader)\n",
      "Cell \u001b[0;32mIn[58], line 14\u001b[0m, in \u001b[0;36mtrain_diff\u001b[0;34m(epoch, model, optimizer, loss_function, train_loader)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39mfor\u001b[39;00m idx, x \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(data):\n\u001b[1;32m     13\u001b[0m     \u001b[39minput\u001b[39m[idx] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msqrt(alf[idx]) \u001b[39m*\u001b[39m data[idx] \u001b[39m+\u001b[39m torch\u001b[39m.\u001b[39msqrt(\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m alf[idx]) \u001b[39m*\u001b[39m eps[idx]\n\u001b[0;32m---> 14\u001b[0m eps_nn \u001b[39m=\u001b[39m model(\u001b[39minput\u001b[39;49m\u001b[39m.\u001b[39;49mview(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m, \u001b[39m28\u001b[39;49m, \u001b[39m28\u001b[39;49m), t)\n\u001b[1;32m     15\u001b[0m loss \u001b[39m=\u001b[39m loss_function(eps\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m784\u001b[39m), eps_nn\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m784\u001b[39m))\n\u001b[1;32m     16\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[57], line 115\u001b[0m, in \u001b[0;36mDiffusionModel.forward\u001b[0;34m(self, x, t)\u001b[0m\n\u001b[1;32m    113\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(x)\n\u001b[1;32m    114\u001b[0m \u001b[39mprint\u001b[39m(x\u001b[39m.\u001b[39mshape)\n\u001b[0;32m--> 115\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mc7(x) \u001b[39m+\u001b[39m T\n\u001b[1;32m    116\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mb7(x)\n\u001b[1;32m    117\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(x)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    460\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [10, 1, 3, 3], expected input[512, 10, 28, 28] to have 1 channels, but got 10 channels instead"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "for epoch in range(EPOCHS):\n",
    "    train_diff(epoch, model, optimizer, loss, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = model.sample_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f836919ec80>"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sigmoid = nn.Sigmoid()\n",
    "plt.imshow(test[0].view(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedtime(self, t, embedding_size, dimensions):\n",
    "    emb = torch.zeros((embedding_size // 2) * t.shape[0]).reshape(t.shape[0], embedding_size // 2)\n",
    "    emb2 = torch.zeros((embedding_size // 2) * t.shape[0]).reshape(t.shape[0], embedding_size // 2)\n",
    "    s = torch.linspace(torch.tensor(2), torch.tensor(embedding_size // 2), torch.tensor(embedding_size // 2, dtype=int))\n",
    "    for idx, samp in enumerate(t):\n",
    "        emb[idx] = torch.sin(2 * s * torch.pi * samp / self.T)\n",
    "        emb2[idx] = torch.cos(2 * s * torch.pi * samp / self.T)\n",
    "\n",
    "    return torch.cat([emb, emb2], dim = 1).view(-1, embedding_size, 1, 1).repeat(1, 1, dimensions, dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 8, 8])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 8])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_encoding(self, t, channels, embed_size):\n",
    "        inv_freq = 1.0 / (\n",
    "            10000\n",
    "            ** (torch.arange(0, channels, 2, device=self.device).float() / channels)\n",
    "        )\n",
    "        pos_enc_a = torch.sin(t.repeat(1, channels // 2) * inv_freq)\n",
    "        pos_enc_b = torch.cos(t.repeat(1, channels // 2) * inv_freq)\n",
    "        pos_enc = torch.cat([pos_enc_a, pos_enc_b], dim=-1)\n",
    "        return pos_enc.view(-1, channels, 1, 1).repeat(1, 1, embed_size, embed_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 16])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([2]).repeat(1, 32 // 2) * torch.arange(0, 32, 2)\n",
    "b = a = torch.tensor([2]).repeat(1, 32 // 2) * torch.arange(0, 32, 2)\n",
    "torch.cat([a, b], dim = 1).view(-1, 32, 1, 1).repeat(1, 1, 16, 16)[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
