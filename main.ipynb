{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyro.optim import Adam\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "import pyro\n",
    "import torch\n",
    "import VAE\n",
    "import ConvEncoderDecoder as CED\n",
    "import LinearEncoderDecoder as LED\n",
    "\n",
    "from pyro.contrib.examples.util import MNIST\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_data_loaders(batch_size=128, use_cuda=False):\n",
    "    root = './data'\n",
    "    download = True\n",
    "    trans = transforms.ToTensor()\n",
    "    train_set = MNIST(root=root, train=True, transform=trans,\n",
    "                      download=download)\n",
    "    test_set = MNIST(root=root, train=False, transform=trans)\n",
    "\n",
    "    kwargs = {'num_workers': 1, 'pin_memory': use_cuda}\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_set,\n",
    "        batch_size=batch_size, shuffle=True, **kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_set,\n",
    "        batch_size=batch_size, shuffle=False, **kwargs)\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(svi, train_loader, use_cuda=False):\n",
    "    # initialize loss accumulator\n",
    "    epoch_loss = 0.\n",
    "    # do a training epoch over each mini-batch x returned\n",
    "    # by the data loader\n",
    "    for x, _ in train_loader:\n",
    "        # if on GPU put mini-batch into CUDA memory\n",
    "        if use_cuda:\n",
    "            x = x.cuda()\n",
    "        # do ELBO gradient and accumulate loss\n",
    "        epoch_loss += svi.step(x)\n",
    "\n",
    "    # return epoch loss\n",
    "    normalizer_train = len(train_loader.dataset)\n",
    "    total_epoch_loss_train = epoch_loss / normalizer_train\n",
    "    return total_epoch_loss_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(svi, test_loader, use_cuda=False):\n",
    "    # initialize loss accumulator\n",
    "    test_loss = 0.\n",
    "    # compute the loss over the entire test set\n",
    "    for x, _ in test_loader:\n",
    "        # if on GPU put mini-batch into CUDA memory\n",
    "        if use_cuda:\n",
    "            x = x.cuda()\n",
    "        # compute ELBO estimate and accumulate loss\n",
    "        test_loss += svi.evaluate_loss(x)\n",
    "    normalizer_test = len(test_loader.dataset)\n",
    "    total_epoch_loss_test = test_loss / normalizer_test\n",
    "    return total_epoch_loss_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 000]  average training loss: 226.9806\n",
      "[epoch 000] average test loss: 190.9529\n",
      "[epoch 001]  average training loss: 189.5039\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39m# training loop\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(NUM_EPOCHS):\n\u001b[0;32m---> 19\u001b[0m     total_epoch_loss_train \u001b[39m=\u001b[39m train(svi, train_loader, use_cuda\u001b[39m=\u001b[39;49mUSE_CUDA)\n\u001b[1;32m     20\u001b[0m     train_elbo\u001b[39m.\u001b[39mappend(\u001b[39m-\u001b[39mtotal_epoch_loss_train)\n\u001b[1;32m     21\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m[epoch \u001b[39m\u001b[39m%03d\u001b[39;00m\u001b[39m]  average training loss: \u001b[39m\u001b[39m%.4f\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (epoch, total_epoch_loss_train))\n",
      "Cell \u001b[0;32mIn[3], line 11\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(svi, train_loader, use_cuda)\u001b[0m\n\u001b[1;32m      9\u001b[0m         x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mcuda()\n\u001b[1;32m     10\u001b[0m     \u001b[39m# do ELBO gradient and accumulate loss\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m     epoch_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m svi\u001b[39m.\u001b[39;49mstep(x)\n\u001b[1;32m     13\u001b[0m \u001b[39m# return epoch loss\u001b[39;00m\n\u001b[1;32m     14\u001b[0m normalizer_train \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(train_loader\u001b[39m.\u001b[39mdataset)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyro/infer/svi.py:145\u001b[0m, in \u001b[0;36mSVI.step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[39m# get loss and compute gradients\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[39mwith\u001b[39;00m poutine\u001b[39m.\u001b[39mtrace(param_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39mas\u001b[39;00m param_capture:\n\u001b[0;32m--> 145\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloss_and_grads(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mguide, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    147\u001b[0m params \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(\n\u001b[1;32m    148\u001b[0m     site[\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39munconstrained() \u001b[39mfor\u001b[39;00m site \u001b[39min\u001b[39;00m param_capture\u001b[39m.\u001b[39mtrace\u001b[39m.\u001b[39mnodes\u001b[39m.\u001b[39mvalues()\n\u001b[1;32m    149\u001b[0m )\n\u001b[1;32m    151\u001b[0m \u001b[39m# actually perform gradient steps\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[39m# torch.optim objects gets instantiated for any params that haven't been seen yet\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyro/infer/trace_elbo.py:157\u001b[0m, in \u001b[0;36mTrace_ELBO.loss_and_grads\u001b[0;34m(self, model, guide, *args, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[39mif\u001b[39;00m trainable_params \u001b[39mand\u001b[39;00m \u001b[39mgetattr\u001b[39m(\n\u001b[1;32m    154\u001b[0m         surrogate_loss_particle, \u001b[39m\"\u001b[39m\u001b[39mrequires_grad\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    155\u001b[0m     ):\n\u001b[1;32m    156\u001b[0m         surrogate_loss_particle \u001b[39m=\u001b[39m surrogate_loss_particle \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_particles\n\u001b[0;32m--> 157\u001b[0m         surrogate_loss_particle\u001b[39m.\u001b[39;49mbackward(retain_graph\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretain_graph)\n\u001b[1;32m    158\u001b[0m warn_if_nan(loss, \u001b[39m\"\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    159\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    489\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    490\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "USE_CUDA = False\n",
    "NUM_EPOCHS = 20\n",
    "TEST_FREQUENCY = 5\n",
    "train_loader, test_loader = setup_data_loaders(batch_size=256, use_cuda=USE_CUDA)\n",
    "\n",
    "# clear param store\n",
    "pyro.clear_param_store()\n",
    "\n",
    "#model = VAE.VAE(LED.LinearEncoder(2, 400, 100), LED.LinearDecoder(2, 400, 100))\n",
    "model = VAE.VAE(CED.ConvEncoder(2, 16), CED.ConvDecoder(2, 16))\n",
    "\n",
    "optimizer = Adam({\"lr\": 1.0e-2})\n",
    "svi = SVI(model.model, model.guide, optimizer, loss=Trace_ELBO())\n",
    "\n",
    "train_elbo = []\n",
    "test_elbo = []\n",
    "# training loop\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    total_epoch_loss_train = train(svi, train_loader, use_cuda=USE_CUDA)\n",
    "    train_elbo.append(-total_epoch_loss_train)\n",
    "    print(\"[epoch %03d]  average training loss: %.4f\" % (epoch, total_epoch_loss_train))\n",
    "\n",
    "    if epoch % TEST_FREQUENCY == 0:\n",
    "        # report test diagnostics\n",
    "        total_epoch_loss_test = evaluate(svi, test_loader, use_cuda=USE_CUDA)\n",
    "        test_elbo.append(-total_epoch_loss_test)\n",
    "        print(\"[epoch %03d] average test loss: %.4f\" % (epoch, total_epoch_loss_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "s = model.decoder(torch.randn(1, 2)).detach().numpy().reshape(28, 28)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(s)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
